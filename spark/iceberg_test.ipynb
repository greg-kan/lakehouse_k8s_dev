{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ea1a22-80d5-42ca-bf82-4a330c0cf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4a4957-d431-4aac-90ff-31c931a97eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libcap2-bin libpam-cap\n",
      "The following NEW packages will be installed:\n",
      "  iputils-ping libcap2-bin libpam-cap\n",
      "0 upgraded, 3 newly installed, 0 to remove and 1 not upgraded.\n",
      "Need to get 76.9 kB of archives.\n",
      "After this operation, 280 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcap2-bin amd64 1:2.44-1ubuntu0.22.04.2 [26.0 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 iputils-ping amd64 3:20211215-1ubuntu0.1 [43.0 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpam-cap amd64 1:2.44-1ubuntu0.22.04.2 [7930 B]\n",
      "Fetched 76.9 kB in 2s (50.1 kB/s)   \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libcap2-bin.\n",
      "(Reading database ... 17759 files and directories currently installed.)\n",
      "Preparing to unpack .../libcap2-bin_1%3a2.44-1ubuntu0.22.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libcap2-bin (1:2.44-1ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package iputils-ping.\n",
      "Preparing to unpack .../iputils-ping_3%3a20211215-1ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking iputils-ping (3:20211215-1ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libpam-cap:amd64.\n",
      "Preparing to unpack .../libpam-cap_1%3a2.44-1ubuntu0.22.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking libpam-cap:amd64 (1:2.44-1ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Setting up libcap2-bin (1:2.44-1ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libpam-cap:amd64 (1:2.44-1ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up iputils-ping (3:20211215-1ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "! apt install iputils-ping -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c68e01-ba91-4b43-abf8-f5e5017fe36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING 10.107.38.26 (10.107.38.26) 56(84) bytes of data.\n"
     ]
    }
   ],
   "source": [
    "! ping 10.107.38.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8608813c-b7c6-49b1-8043-6575f4af60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE VARIABLES\n",
    "# CATALOG_URI = \"http://nessie-service.nessie-dev.svc.cluster.local:19120/api/v1\"\n",
    "CATALOG_URI = \"http://nessie-service.nessie-dev.svc.cluster.local:6788/api/v1\"\n",
    "# WAREHOUSE = \"s3://iceberg/\"\n",
    "WAREHOUSE = \"s3a://iceberg/\"\n",
    "# STORAGE_URI = \"http://minio.minio-dev.svc.cluster.local:9000\"\n",
    "# STORAGE_URI = \"http://minio-service.minio-dev.svc.cluster.local:6544\"\n",
    "# to define ip run: kubectl get svc -n minio-dev\n",
    "STORAGE_URI = \"http://10.107.38.26:6544\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627692e8-8037-4521-969b-b9ea3356c302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minio\n"
     ]
    }
   ],
   "source": [
    "MINIO_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "print(MINIO_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3693eb7a-281f-46c7-a4a6-185b48af51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURE SPARK SESSION\n",
    "        # .set('spark.jars.packages', \n",
    "        #      'org.postgresql:postgresql:42.7.3,'\n",
    "        #      'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,'\n",
    "        #      'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,'\n",
    "        #      'org.apache.hadoop:hadoop-aws:3.3.4,'\n",
    "        #      'software.amazon.awssdk:bundle:2.24.8,'\n",
    "        #      'software.amazon.awssdk:url-connection-client:2.24.8')             \n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('Iceberg Ingestion')\n",
    "        .set('spark.sql.extensions', \n",
    "             'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,'\n",
    "             'org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', CATALOG_URI)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', STORAGE_URI)\n",
    "        .set('spark.sql.catalog.nessie.warehouse', WAREHOUSE)\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "        .set(\"spark.hadoop.fs.s3a.endpoint\", STORAGE_URI)\n",
    "        .set(\"spark.hadoop.fs.s3a.access.key\", MINIO_ACCESS_KEY)\n",
    "        .set(\"spark.hadoop.fs.s3a.secret.key\", MINIO_SECRET_KEY)\n",
    "        .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "        .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2755435-0ca2-4526-a374-47cc89e47222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/17 19:18:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n"
     ]
    }
   ],
   "source": [
    "## START SPARK SESSION\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"Spark Running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36190168-7357-41ce-aebd-34a34ff44135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the JDBC connection properties\n",
    "jdbc_url = \"jdbc:postgresql://postgres.psql-dev.svc.cluster.local:5432/postgres\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df6eccf-c856-4005-bfab-44cfa1dc736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = spark.read.jdbc(url=jdbc_url, table=\"fashion_sales\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e91918-cb13-46ce-b014-a58076f089b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "| id|   product_name| category|sales_amount|sales_date|store_location|customer_age_group|campaign_name|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "|  1| Slim Fit Jeans|    Denim|       89.99|2024-03-01|      New York|             18-24|Spring Launch|\n",
      "|  2| Leather Jacket|Outerwear|      249.99|2024-03-01|   Los Angeles|             25-34|Spring Launch|\n",
      "|  3|Graphic T-Shirt|     Tops|       39.99|2024-03-02|       Chicago|             18-24|March Madness|\n",
      "|  4|   Summer Dress|  Dresses|      129.99|2024-03-03|      New York|             35-44|March Madness|\n",
      "|  5|Casual Sneakers| Footwear|       99.99|2024-03-03|   Los Angeles|             25-34|Spring Launch|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3533710b-aff0-4522-b626-9f64bffff1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"/workspace/out\" \n",
    "# sales_df.write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "609aac2e-be97-4b7b-b651-8a05275b5c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/17 19:19:05 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "| id|   product_name| category|sales_amount|sales_date|store_location|customer_age_group|campaign_name|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "|  1| Slim Fit Jeans|    Denim|       89.99|2024-03-01|      New York|             18-24|Spring Launch|\n",
      "|  2| Leather Jacket|Outerwear|      249.99|2024-03-01|   Los Angeles|             25-34|Spring Launch|\n",
      "|  3|Graphic T-Shirt|     Tops|       39.99|2024-03-02|       Chicago|             18-24|March Madness|\n",
      "|  4|   Summer Dress|  Dresses|      129.99|2024-03-03|      New York|             35-44|March Madness|\n",
      "|  5|Casual Sneakers| Footwear|       99.99|2024-03-03|   Los Angeles|             25-34|Spring Launch|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"src\"\n",
    "FILE_PATH = \"data/parquet/part-00000.snappy.parquet\"\n",
    "\n",
    "s3a_path = f\"s3a://{BUCKET_NAME}/{FILE_PATH}\"\n",
    "\n",
    "df = spark.read.parquet(s3a_path)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501cc692-57a9-4000-8cb3-4ce467b3c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sparkContext._jvm.org.apache.hadoop.util.VersionInfo.getVersion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8988dd-ea44-40d5-a111-691821d3cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.sales;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f420b2-4761-40dd-ae0e-ac75d56983f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.writeTo(\"nessie.sales.fashion_sales\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66b030bb-fa94-477d-b213-ab3ccfd437e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "| id|   product_name| category|sales_amount|sales_date|store_location|customer_age_group|campaign_name|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "|  1| Slim Fit Jeans|    Denim|       89.99|2024-03-01|      New York|             18-24|Spring Launch|\n",
      "|  2| Leather Jacket|Outerwear|      249.99|2024-03-01|   Los Angeles|             25-34|Spring Launch|\n",
      "|  3|Graphic T-Shirt|     Tops|       39.99|2024-03-02|       Chicago|             18-24|March Madness|\n",
      "|  4|   Summer Dress|  Dresses|      129.99|2024-03-03|      New York|             35-44|March Madness|\n",
      "|  5|Casual Sneakers| Footwear|       99.99|2024-03-03|   Los Angeles|             25-34|Spring Launch|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"nessie.sales.fashion_sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae0fff7c-c17f-47e7-b4b0-61278d9f524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.writeTo(\"nessie.sales.fashion_sales_temp\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "372cd728-8140-4641-8719-e233d6b174a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "| id|   product_name| category|sales_amount|sales_date|store_location|customer_age_group|campaign_name|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "|  1| Slim Fit Jeans|    Denim|       89.99|2024-03-01|      New York|             18-24|Spring Launch|\n",
      "|  2| Leather Jacket|Outerwear|      249.99|2024-03-01|   Los Angeles|             25-34|Spring Launch|\n",
      "|  3|Graphic T-Shirt|     Tops|       39.99|2024-03-02|       Chicago|             18-24|March Madness|\n",
      "|  4|   Summer Dress|  Dresses|      129.99|2024-03-03|      New York|             35-44|March Madness|\n",
      "|  5|Casual Sneakers| Footwear|       99.99|2024-03-03|   Los Angeles|             25-34|Spring Launch|\n",
      "+---+---------------+---------+------------+----------+--------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"nessie.sales.fashion_sales_temp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e64303c-50ea-4b53-80e7-3fb6503453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318589a-0765-4018-9b84-14e6723d3ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
